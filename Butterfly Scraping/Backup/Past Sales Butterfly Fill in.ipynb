{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 1\n",
    "base_folder = 'Butterfly Past Low Priority June'\n",
    "mypath = base_folder+\"/past sales\"\n",
    "files = [mypath+'/'+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "files.sort()\n",
    "files = files[200*(part-1):200*(part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:30:07<00:00, 27.04s/it]   \n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    if '.csv' not in file:\n",
    "        continue\n",
    "    try:\n",
    "        data = pd.read_csv(file)\n",
    "    except:\n",
    "        print(file)\n",
    "        \n",
    "\n",
    "    # loop through data\n",
    "    #for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        link = row['link']\n",
    "        \n",
    "        # Detailed Scraping\n",
    "        deeper_info = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "        \n",
    "        # Get seller info\n",
    "        try:\n",
    "            seller_info = deeper_info.find_all('div', class_='si-content')[0]\n",
    "            seller_name = seller_info.find_all('span', class_='mbg-nw')[0].text\n",
    "            seller_link = seller_info.find_all('a')[0].get('href')\n",
    "        except:\n",
    "            seller_name = 'Unknown'\n",
    "            seller_link = 'Unknown'\n",
    "\n",
    "        # Get sales type, num bids and num sold\n",
    "        try:\n",
    "            #num_bids = deeper_info.find('a', id='vi-VR-bid-lnk').find_all('span')[0].text.strip()\n",
    "            num_bids = deeper_info.find('div',id='mainContent').find_all('span', text=re.compile(\"bid\"))[0].parent()[0].text.strip()\n",
    "            auction_end_date = deeper_info.find('span', id='bb_tlft').text.strip()\n",
    "            sell_type = 'Auction'\n",
    "            num_sold = 1\n",
    "        except:\n",
    "            sell_type = 'Instant'\n",
    "            num_bids = 0\n",
    "            auction_end_date = None\n",
    "            try:\n",
    "                num_sold = deeper_info.find('div',id='mainContent').find_all('a', text=re.compile(\"sold\"))[0].text.strip().replace(' sold','')\n",
    "            except:\n",
    "                num_sold = 1\n",
    "                \n",
    "        # Get locality\n",
    "        try:\n",
    "            origin = deeper_info.find('div',id='mainContent').find_all('div', text=re.compile(\"Item location\"))[0].parent()[1].text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                origin = deeper_info.find('div',id='mainContent').find_all('div', text=re.compile(\"Located in\"))[0].parent()[1].text.strip()\n",
    "            except:\n",
    "                origin = 'Unknown'\n",
    "\n",
    "        # Description\n",
    "        #description_src = deeper_info.find_all('iframe')[0].get('src')\n",
    "        #description = ' '.join(BeautifulSoup(requests.get(description_src).content, 'html.parser').find('div', id='ds_div').text.strip().split())\n",
    "\n",
    "        # save data\n",
    "        data.loc[index,'auction_end_date'] = auction_end_date\n",
    "        data.loc[index, 'sell_type'] = sell_type\n",
    "        data.loc[index, 'num_bids'] = num_bids\n",
    "        data.loc[index, 'num_sold'] = num_sold\n",
    "        data.loc[index, 'origin'] = origin\n",
    "        data.loc[index, 'seller_name'] = seller_name\n",
    "        data.loc[index, 'seller_link'] = seller_link\n",
    "        \n",
    "    \n",
    "    data.to_csv(file,index=False, encoding='utf-8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
